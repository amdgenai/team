- title: "GEAK-Triton v2 Family of AI Agents: Kernel Optimization for AMD Instinct GPUs"
  excerpt: "Announcing GEAK-OptimAgentv2 and GEAK-OpenEvolve AI agents for generating Triton kernels optimized for AMD Instinct GPUs, featuring multi-offspring evolution, hardware-aware feedback, and quality-diversity search for up to 3.42× speedups."
  date: "December 23, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/geak-agents-family/README.html"
  background_image: "/assets/images/blog-bg-geak-v2.png"

- title: "GEAK-HIP: Expanding GEAK for HIP Code Optimization"
  excerpt: "Extending the GEAK family to native HIP code generation and optimization, enabling AI-driven kernel development for AMD Instinct GPUs with similar techniques applied to HIP kernels."
  date: "December 23, 2025"
  url: "https://rocm.blogs.amd.com/software-tools-optimization/geak-hip-optimizations/README.html"
  background_image: "/assets/images/blog-bg-geak-hip.png"

- title: "SAND-Math: Building a 32B Reasoning Model with Synthetic Data"
  excerpt: "Building a state-of-the-art 32B reasoning model on AMD Instinct™ MI325X GPUs using only synthetic data. SAND-MathScience-DeepSeek-Qwen32B achieves 78.33% on AIME25, surpassing Qwen3-32B, with fully open-sourced model weights, datasets, and training code."
  date: "December 06, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/sand-math/README.html"
  background_image: "/assets/images/blog-bg-sand.png"

- title: "slime: SGLang-Native RL Framework on AMD GPUs"
  excerpt: "AMD provides Day-0 support for slime, the SGLang-native RL framework verified for large-scale MoE models up to 355B parameters. Features APRIL optimization achieving 40% throughput improvement, Docker deployment, and multi-turn kernel-agent training on AMD Instinct™ GPUs."
  date: "September 25, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/slime/README.html"
  background_image: "/assets/images/blog-bg-slime.png"

- title: "Instella-Math"
  excerpt: "Introducing Instella-Math — AMD's first fully open reasoning language model, trained end-to-end with long chain-of-thought reinforcement learning on 32 MI300X GPUs. Optimized for complex reasoning and math, with all code, weights, and datasets released for the community."
  date: "August 9, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/instella-math-language/README.html"
  background_image: "/assets/images/blog-bg-math.png"

- title: "GEAK: Triton Kernel AI Agent"
  excerpt: "Introducing GEAK, AMD’s AI-driven Triton kernel generation framework and evaluation benchmarks. GEAK leverages frontier LLMs with inference-time scaling to automatically produce efficient, accurate GPU kernels for AMD Instinct™ GPUs, achieving up to 63% correctness and 2.59× speedups over reference implementations."
  date: "August 1, 2025"
  url: "https://rocm.blogs.amd.com/software-tools-optimization/triton-kernel-ai/README.html"
  background_image: "/assets/images/blog-bg-geak.png"

- title: "Instella-T2I"
  excerpt: "Introducing 1D binary image latents for text-to-image generation, achieving up to 32× token reduction and competitive 1024×1024 performance with faster, scalable training and inference."
  date: "July 15, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/instella-t2i/README.html"
  background_image: "/assets/images/blog-bg-t2i.png"

- title: "Instella-Long"
  excerpt: "Introducing Instella-Long, a fully open 3B-parameter language model supporting 128K context length, trained on 64 Instinct MI300X GPUs with open-sourced weights, data, and code, showcasing AMD hardware’s scalability and enabling community-driven long-context AI research."
  date: "June 11, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/instella-long-context/README.html"
  background_image: "/assets/images/blog-bg-long.png"

- title: "VeRL on AMD GPUs"
  excerpt: "Overview of Volcano Engine Reinforcement Learning (verl) for large-scale RLHF on AMD Instinct GPUs. Learn about AMD-specific optimizations, Docker setup, and training scripts for single-node and multi-node deployments, plus performance benchmarks on MI300X."
  date: "April 24, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html"
  background_image: "/assets/images/blog-bg-verl.png"

- title: "Instella-VL-1B"
  excerpt: "Introducing Instella-VL-1B, the first open-source vision-language model trained on MI300X GPUs, combining a CLIP-based vision encoder with a 1B-parameter language model and outperforming comparable open-weight models on general and OCR benchmarks, with full weights, data, and code released for the community."
  date: "March 07, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/Instella-BL-1B-VLM/README.html"
  background_image: "/assets/images/blog-bg-vl.png"

- title: "Instella-3B"
  excerpt: "Introducing Instella, a fully open family of 3B-parameter language models trained from scratch on MI300X GPUs, outperforming similar open models and achieving competitive performance with state-of-the-art open-weight models, with all weights, data, and code released to the community."
  date: "March 05, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/introducing-instella-3B/README.html"
  background_image: "/assets/images/blog-bg-ins3.png"

- title: "AMD-OLMo-1B"
  excerpt: "Introducing AMD OLMo, a fully open series of 1B-parameter language models trained from scratch on MI250 GPUs with 1.3T tokens, featuring pre-trained, SFT, and DPO checkpoints, empowering the AI community with reproducible training details and efficient deployment on AMD hardware."
  date: "October 31, 2024"
  url: "https://www.amd.com/en/developer/resources/technical-articles/introducing-the-first-amd-1b-language-model.html"