- title: "Instella-Math"
  excerpt: "Introducing Instella-Math — AMD’s first fully open reasoning language model, trained end-to-end with long chain-of-thought reinforcement learning on 32 MI300X GPUs. Optimized for complex reasoning and math, with all code, weights, and datasets released for the community."
  date: "August 9, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/instella-math-language/README.html"
  background_image: "/assets/images/blog-bg-math.png"

- title: "GEAK: Triton Kernel AI Agent"
  excerpt: "Introducing GEAK, AMD’s AI-driven Triton kernel generation framework and evaluation benchmarks. GEAK leverages frontier LLMs with inference-time scaling to automatically produce efficient, accurate GPU kernels for AMD Instinct™ GPUs, achieving up to 63% correctness and 2.59× speedups over reference implementations."
  date: "August 1, 2025"
  url: "https://rocm.blogs.amd.com/software-tools-optimization/triton-kernel-ai/README.html"
  background_image: "/assets/images/blog-bg-geak.png"

- title: "Instella-T2I"
  excerpt: "Introducing 1D binary image latents for text-to-image generation, achieving up to 32× token reduction and competitive 1024×1024 performance with faster, scalable training and inference."
  date: "July 15, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/instella-t2i/README.html"
  background_image: "/assets/images/blog-bg-t2i.png"

- title: "Instella-Long"
  excerpt: "Introducing Instella-Long, a fully open 3B-parameter language model supporting 128K context length, trained on 64 Instinct MI300X GPUs with open-sourced weights, data, and code, showcasing AMD hardware’s scalability and enabling community-driven long-context AI research."
  date: "June 11, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/instella-long-context/README.html"
  background_image: "/assets/images/blog-bg-long.png"

- title: "VeRL on AMD GPUs"
  excerpt: "Overview of Volcano Engine Reinforcement Learning (verl) for large-scale RLHF on AMD Instinct GPUs. Learn about AMD-specific optimizations, Docker setup, and training scripts for single-node and multi-node deployments, plus performance benchmarks on MI300X."
  date: "April 24, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html"
  background_image: "/assets/images/blog-bg-verl.png"

- title: "Instella-VL-1B"
  excerpt: "Introducing Instella-VL-1B, the first open-source vision-language model trained on MI300X GPUs, combining a CLIP-based vision encoder with a 1B-parameter language model and outperforming comparable open-weight models on general and OCR benchmarks, with full weights, data, and code released for the community."
  date: "March 07, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/Instella-BL-1B-VLM/README.html"
  background_image: "/assets/images/blog-bg-vl.png"

- title: "Instella-3B"
  excerpt: "Introducing Instella, a fully open family of 3B-parameter language models trained from scratch on MI300X GPUs, outperforming similar open models and achieving competitive performance with state-of-the-art open-weight models, with all weights, data, and code released to the community."
  date: "March 05, 2025"
  url: "https://rocm.blogs.amd.com/artificial-intelligence/introducing-instella-3B/README.html"
  background_image: "/assets/images/blog-bg-ins3.png"

- title: "AMD-OLMo-1B"
  excerpt: "Introducing AMD OLMo, a fully open series of 1B-parameter language models trained from scratch on MI250 GPUs with 1.3T tokens, featuring pre-trained, SFT, and DPO checkpoints, empowering the AI community with reproducible training details and efficient deployment on AMD hardware."
  date: "October 31, 2024"
  url: "https://www.amd.com/en/developer/resources/technical-articles/introducing-the-first-amd-1b-language-model.html"